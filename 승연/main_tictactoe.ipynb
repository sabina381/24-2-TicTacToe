{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS 장치를 지원하도록 build가 되었는가? True\n",
      "MPS 장치가 사용 가능한가? True\n"
     ]
    }
   ],
   "source": [
    "print(f\"MPS 장치를 지원하도록 build가 되었는가? {torch.backends.mps.is_built()}\")\n",
    "print(f\"MPS 장치가 사용 가능한가? {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/seungyeonlee/Documents/GitHub/24-2-TicTacToe/승연')\n",
    "from config import *\n",
    "\n",
    "from enemy_agents import *\n",
    "from environment import *\n",
    "from evaluate import *\n",
    "from file_save_load import *\n",
    "from mcts import *\n",
    "from net import *\n",
    "from train_network import *\n",
    "from visualizing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Environment\n",
      "STATE_SIZE = (3, 3)\n",
      "WIN_CONDITION = 3\n",
      "F_PATH = /Users/seungyeonlee/Documents/GitHub/24-2-TicTacToe/승연/train_files\n",
      "F_NAME = 250218-4\n",
      "\n",
      "ALLOW_TRANSPOSE = True\n",
      "DATA_AGUMENTATION = True\n",
      "\n",
      "# state\n",
      "NUM_HISTORY = 1\n",
      "PLAYER_INFO = False\n",
      "\n",
      "# enemy agents\n",
      "AB_DEPTH = 100\n",
      "MCS_PO_NUM =100\n",
      "MCTS_EV_NUM = 100\n",
      "\n",
      "# net\n",
      "ACTION_SIZE = 9\n",
      "STATE_DIM = 4\n",
      "\n",
      "CONV_UNITS = 64\n",
      "RESIDUAL_NUM = 8\n",
      "\n",
      "DEVICE = mps\n",
      "\n",
      "# mcts\n",
      "C_PUCT = 5\n",
      "EVAL_CNT = 200\n",
      "TEMPERATURE = 1.0\n",
      "TEMPERATURE_DECAY = 0.9\n",
      "\n",
      "# train\n",
      "LEARN_RATE = 0.001\n",
      "GAMMA = 0.2\n",
      "TOTAL_SP_NUM = 100\n",
      "SP_NUM_TRAIN = 1\n",
      "EXPLORE_REGULATION = 4\n",
      "\n",
      "CROSS_ENTROPY = CrossEntropyLoss()\n",
      "\n",
      "BATCHSIZE = 256\n",
      "TRAIN_EPOCHS = 10\n",
      "MEM_SIZE = 30000\n",
      "\n",
      "EPISODES = 100\n",
      "\n",
      "# evaluation\n",
      "EVAL_NUM_GAME = 20\n",
      "TEST_NUM_GAME = 10\n",
      "CRITERIA = 0.5\n",
      "\n",
      "EVAL_FREQUENCY = 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/seungyeonlee/Documents/GitHub/24-2-TicTacToe/승연/train_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Create '250218-4_model_latest.pkl'\n",
      "    Create '250218-4_history.pkl'\n"
     ]
    }
   ],
   "source": [
    "model_type = ResNet()\n",
    "env = Environment(STATE_SIZE, WIN_CONDITION)\n",
    "eval = Evaluate(F_NAME, model_type)\n",
    "Train = TrainNetwork(F_NAME, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.train_cycle(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Load model from '250218-1_model_latest.pkl'\n",
      ". . . \n",
      ". . . \n",
      ". . .\n",
      "----------\n",
      ". . . \n",
      ". . . \n",
      "○ . .\n",
      "----------\n",
      ". . . \n",
      ". . . \n",
      "○ ● .\n",
      "----------\n",
      ". . . \n",
      "○ . . \n",
      "○ ● .\n",
      "----------\n",
      "● . . \n",
      "○ . . \n",
      "○ ● .\n",
      "----------\n",
      "● . . \n",
      "○ ○ . \n",
      "○ ● .\n",
      "----------\n",
      "● . . \n",
      "○ ○ ● \n",
      "○ ● .\n",
      "----------\n",
      "reward of agent: 1\n"
     ]
    }
   ],
   "source": [
    "env = Environment(STATE_SIZE, WIN_CONDITION)\n",
    "model = load_model(\"250218-1_model_latest.pkl\")\n",
    "agent = Mcts(model, 0.0)\n",
    "\n",
    "is_done = False\n",
    "n_steps = 0\n",
    "state = State()\n",
    "\n",
    "while not is_done:\n",
    "    n_steps += 1\n",
    "    env.render(state)\n",
    "    print(\"-\"*10)\n",
    "\n",
    "    if n_steps % 2 == 0:\n",
    "        action = agent.get_action(state)\n",
    "    else:\n",
    "        action = int(input(\"choose action (0~8):\"))\n",
    "\n",
    "    state, is_done, is_lose = env.step(state, action)\n",
    "\n",
    "reward = env.get_first_reward(state)\n",
    "print(f\"reward of agent: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80f3ce62248fa450f65fa83724ba9cb1496b6411704937f1b6e1f2130379b287"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
